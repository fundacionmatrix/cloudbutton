{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:indigo\">*Entrenamiento para clasificar cobertura del suelo utilizando Spark</h1>\n",
    "<p>Autor: <a href=\"https://www.linkedin.com/in/albertoav\" style=\"text-decoration:none;\">Alberto Álvarez Vales</a>     \n",
    "</p>\n",
    "Fecha: 22/03/2019\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopandas import read_file,GeoDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext.getOrCreate()\n",
    "from pyspark.sql import SQLContext\n",
    "spark = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datosGlobales=read_file(\"segmented_TopFixed.gpkg\")\n",
    "datosEntrenamiento=read_file(\"ForClassifySegments.gpkg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfGlobal=spark.createDataFrame(datosGlobales)\n",
    "dfEntrenamiento=spark.createDataFrame(datosEntrenamiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---------+--------------+--------+-----------+------------------+---------+------------------+------+------+------------------+--------+------------------+---------+------------------+------+------+------------------+---------+------------------+---------+------------------+------+------+------------------+--------------------+\n",
      "|cat|  area|perimeter|compact_circle|      fd|     B1_sum|           B1_mean|B1_median|          B1_stdev|B1_min|B1_max|       B1_variance|  B2_sum|           B2_mean|B2_median|          B2_stdev|B2_min|B2_max|       B2_variance|   B3_sum|           B3_mean|B3_median|          B3_stdev|B3_min|B3_max|       B3_variance|            geometry|\n",
      "+---+------+---------+--------------+--------+-----------+------------------+---------+------------------+------+------+------------------+--------+------------------+---------+------------------+------+------+------------------+---------+------------------+---------+------------------+------+------+------------------+--------------------+\n",
      "|289|  42.0|     68.0|      2.959916|2.257814|   160002.0|3809.5714285714284|   3809.0|371.78675037594064|3117.0|4483.0|138225.38775510198| 42547.0|1013.0238095238095|    957.5| 316.4624771329242| 587.0|1860.0|100148.49943310658|  40264.0| 958.6666666666666|    918.0| 203.8958261870702| 628.0|1494.0|41573.507936507944|[94649675122792, ...|\n",
      "|  1|2646.0|    314.0|      1.721987|1.459088|1.0677334E7|4035.2736205593346|   4042.0| 356.9895384657182|1689.0|5379.0| 127441.5305739665|863037.0| 326.1666666666667|    292.0|123.88339905268381| 202.0|1516.0|  15347.0965608465|1339869.0|506.37528344671205|    466.0|113.10567761932612| 381.0|1292.0|12792.894309726928|[94649675121992, ...|\n",
      "+---+------+---------+--------------+--------+-----------+------------------+---------+------------------+------+------+------------------+--------+------------------+---------+------------------+------+------+------------------+---------+------------------+---------+------------------+------+------+------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfGlobal.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+------+---------+----------+--------+----+--------------------+\n",
      "|Source| cat|  area|perimeter|compact_ci|      fd|tipo|            geometry|\n",
      "+------+----+------+---------+----------+--------+----+--------------------+\n",
      "| INPUT| 303| 861.0|    244.0|  2.345759|1.626839|   5|[94649983183656, ...|\n",
      "| INPUT|1968|1350.0|    352.0|  2.702532| 1.62701|   5|[94649949367768, ...|\n",
      "+------+----+------+---------+----------+--------+----+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfEntrenamiento.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfE=dfEntrenamiento.select(\"cat\",\"tipo\").join(dfGlobal,\"cat\",\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-------+---------+--------------+--------+-----------+-----------------+---------+------------------+------+------+------------------+-----------+------------------+---------+------------------+------+------+----------------+-----------+-----------------+---------+------------------+------+------+------------------+--------------------+\n",
      "|  cat|tipo|   area|perimeter|compact_circle|      fd|     B1_sum|          B1_mean|B1_median|          B1_stdev|B1_min|B1_max|       B1_variance|     B2_sum|           B2_mean|B2_median|          B2_stdev|B2_min|B2_max|     B2_variance|     B3_sum|          B3_mean|B3_median|          B3_stdev|B3_min|B3_max|       B3_variance|            geometry|\n",
      "+-----+----+-------+---------+--------------+--------+-----------+-----------------+---------+------------------+------+------+------------------+-----------+------------------+---------+------------------+------+------+----------------+-----------+-----------------+---------+------------------+------+------+------------------+--------------------+\n",
      "|36577|   2|11724.0|   4188.0|     10.910982| 1.78026|2.7937412E7|2382.924940293415|   2386.0|190.05344692331315|1630.0|3660.0| 36120.31268743261|1.2671557E7|1080.8219890822245|   1072.0|207.84310349726883| 498.0|2010.0|43198.7556713764|  9513449.0|811.4507847151143|    803.0|114.80453646764154| 490.0|1428.0|13180.081593550036|[94649807333336, ...|\n",
      "|45824|   2|36195.0|  10736.0|     15.918908|1.768437|8.6613175E7| 2392.95966293687|   2388.0|156.97799803315877| 471.0|3150.0|24642.091866498395|4.2157776E7|1164.7403232490676|   1154.0|  196.070974537727| 232.0|2116.0| 38443.827056174|3.2600155E7|900.6811714325183|    892.0| 128.2083192998023| 268.0|1658.0|16437.373137680057|[94649835515816, ...|\n",
      "+-----+----+-------+---------+--------------+--------+-----------+-----------------+---------+------------------+------+------+------------------+-----------+------------------+---------+------------------+------+------+----------------+-----------+-----------------+---------+------------------+------+------+------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfE.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas=['area', 'perimeter',  'fd', 'perimeter', 'compact_circle', 'fd', 'B1_sum', 'B1_mean', 'B1_median', 'B1_stdev', 'B1_min', 'B1_max', 'B1_variance', 'B2_sum', 'B2_mean', 'B2_median', 'B2_stdev', 'B2_min', 'B2_max', 'B2_variance', 'B3_sum', 'B3_mean', 'B3_median', 'B3_stdev', 'B3_min', 'B3_max', 'B3_variance']\n",
    "constructor=VectorAssembler(inputCols=columnas,\n",
    "                            outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEF=constructor.transform(dfE).select(\"cat\",\"features\",\"tipo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "entrena,evalua=dfEF.randomSplit([0.8,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier # este algoritmo es el que ofreció mejores resultados en las pruebas\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier(labelCol=\"tipo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo=rf.fit(entrena)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=modelo.transform(evalua)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---+---+---+---+---+---+---+\n",
      "|tipo_prediction|1.0|2.0|3.0|4.0|5.0|6.0|7.0|\n",
      "+---------------+---+---+---+---+---+---+---+\n",
      "|              1|  8|  0|  3|  0|  0|  0|  0|\n",
      "|              2|  0|  3|  0|  0|  0|  0|  0|\n",
      "|              3|  1|  1| 10|  0|  0|  1|  0|\n",
      "|              4|  0|  0|  1|  4|  0|  0|  0|\n",
      "|              5|  0|  0|  0|  0|  6|  0|  0|\n",
      "|              6|  1|  1|  0|  0|  0| 13|  0|\n",
      "|              7|  0|  1|  0|  0|  0|  3|  5|\n",
      "+---------------+---+---+---+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred.crosstab(\"tipo\",\"prediction\").orderBy(\"tipo_prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluador=MulticlassClassificationEvaluator(labelCol=\"tipo\",metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7903225806451613"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluador.evaluate(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeloOk=rf.fit(dfEF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeloOk.write().overwrite().save(\"modelorf\") #eliminar overwrite() si no se quiere sobreescribir el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script de Python para subir a GitLab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo no es lo bastante bueno, métrica:  0.7454545454545455\n"
     ]
    }
   ],
   "source": [
    "from geopandas import read_file,GeoDataFrame\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier # este algoritmo es el que ofreció mejores resultados en las pruebas\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "spark = SQLContext(sc)\n",
    "\n",
    "datosGlobales=read_file(\"segmented_TopFixed.gpkg\")\n",
    "datosEntrenamiento=read_file(\"ForClassifySegments.gpkg\")\n",
    "\n",
    "dfGlobal=spark.createDataFrame(datosGlobales)\n",
    "dfEntrenamiento=spark.createDataFrame(datosEntrenamiento)\n",
    "dfE=dfEntrenamiento.select(\"cat\",\"tipo\").join(dfGlobal,\"cat\",\"inner\")\n",
    "\n",
    "columnas=['area', 'perimeter',  'fd', 'perimeter', 'compact_circle', 'fd', 'B1_sum', 'B1_mean', 'B1_median', 'B1_stdev', 'B1_min', 'B1_max', 'B1_variance', 'B2_sum', 'B2_mean', 'B2_median', 'B2_stdev', 'B2_min', 'B2_max', 'B2_variance', 'B3_sum', 'B3_mean', 'B3_median', 'B3_stdev', 'B3_min', 'B3_max', 'B3_variance']\n",
    "constructor=VectorAssembler(inputCols=columnas,outputCol=\"features\")\n",
    "\n",
    "dfEF=constructor.transform(dfE).select(\"cat\",\"features\",\"tipo\")\n",
    "\n",
    "entrena,evalua=dfEF.randomSplit([0.8,0.2])\n",
    "\n",
    "rf=RandomForestClassifier(labelCol=\"tipo\")\n",
    "\n",
    "modelo=rf.fit(entrena)\n",
    "\n",
    "pred=modelo.transform(evalua)\n",
    "\n",
    "evaluador=MulticlassClassificationEvaluator(labelCol=\"tipo\",metricName=\"accuracy\")\n",
    "\n",
    "metrica=evaluador.evaluate(pred)\n",
    "\n",
    "if metrica>=0.75:\n",
    "    modeloOk=rf.fit(dfEF)\n",
    "    print(\"Se guarda el modelo a disco (métrica: \",metrica,\")\")\n",
    "    modeloOk.write().overwrite().save(\"modelorf\") #eliminar overwrite() si no se quiere sobreescribir el modelo\n",
    "else:\n",
    "    print(\"El modelo no es lo bastante bueno, métrica: \",metrica)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paralelización\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopandas import read_file,GeoDataFrame\n",
    "from pyspark import SparkContext,SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier # este algoritmo es el que ofreció mejores resultados en las pruebas\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "#conf = (SparkConf().setAppName(\"implicit_benchmark\").setMaster('local[*]').set('spark.driver.memory', '16G'))\n",
    "conf = (SparkConf().setAppName(\"implicit_benchmark\").setMaster('local[*]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se guarda el modelo a disco (métrica:  0.8095238095238095 )\n",
      "Se guarda el modelo a disco (métrica:  0.75 )\n",
      "El modelo no es lo bastante bueno, métrica:  0.7272727272727273\n",
      "Se guarda el modelo a disco (métrica:  0.8518518518518519 )\n",
      "Se guarda el modelo a disco (métrica:  0.84 )\n",
      "Se guarda el modelo a disco (métrica:  0.76 )\n",
      "Se guarda el modelo a disco (métrica:  0.9444444444444444 )\n",
      "13.5 s ± 1.46 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1\n",
    "conf = (SparkConf().setAppName(\"implicit_benchmark\").setMaster('local[1]'))\n",
    "sc = SparkContext.getOrCreate(conf=conf)\n",
    "spark = SQLContext(sc)\n",
    "\n",
    "datosGlobales=read_file(\"segmented_TopFixed.gpkg\")\n",
    "datosEntrenamiento=read_file(\"ForClassifySegments.gpkg\")\n",
    "\n",
    "dfGlobal=spark.createDataFrame(datosGlobales)\n",
    "dfEntrenamiento=spark.createDataFrame(datosEntrenamiento)\n",
    "dfE=dfEntrenamiento.select(\"cat\",\"tipo\").join(dfGlobal,\"cat\",\"inner\")\n",
    "\n",
    "columnas=['area', 'perimeter',  'fd', 'perimeter', 'compact_circle', 'fd', 'B1_sum', 'B1_mean', 'B1_median', 'B1_stdev', 'B1_min', 'B1_max', 'B1_variance', 'B2_sum', 'B2_mean', 'B2_median', 'B2_stdev', 'B2_min', 'B2_max', 'B2_variance', 'B3_sum', 'B3_mean', 'B3_median', 'B3_stdev', 'B3_min', 'B3_max', 'B3_variance']\n",
    "constructor=VectorAssembler(inputCols=columnas,outputCol=\"features\")\n",
    "\n",
    "dfEF=constructor.transform(dfE).select(\"cat\",\"features\",\"tipo\")\n",
    "\n",
    "entrena,evalua=dfEF.randomSplit([0.8,0.2])\n",
    "\n",
    "rf=RandomForestClassifier(labelCol=\"tipo\")\n",
    "\n",
    "modelo=rf.fit(entrena)\n",
    "\n",
    "pred=modelo.transform(evalua)\n",
    "\n",
    "evaluador=MulticlassClassificationEvaluator(labelCol=\"tipo\",metricName=\"accuracy\")\n",
    "\n",
    "metrica=evaluador.evaluate(pred)\n",
    "\n",
    "if metrica>=0.75:\n",
    "    modeloOk=rf.fit(dfEF)\n",
    "    print(\"Se guarda el modelo a disco (métrica: \",metrica,\")\")\n",
    "    modeloOk.write().overwrite().save(\"modelorf\") #eliminar overwrite() si no se quiere sobreescribir el modelo\n",
    "else:\n",
    "    print(\"El modelo no es lo bastante bueno, métrica: \",metrica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se guarda el modelo a disco (métrica:  0.8333333333333334 )\n",
      "El modelo no es lo bastante bueno, métrica:  0.7368421052631579\n",
      "Se guarda el modelo a disco (métrica:  0.8125 )\n",
      "Se guarda el modelo a disco (métrica:  0.8125 )\n",
      "Se guarda el modelo a disco (métrica:  0.8095238095238095 )\n",
      "El modelo no es lo bastante bueno, métrica:  0.7368421052631579\n",
      "El modelo no es lo bastante bueno, métrica:  0.65\n",
      "12.1 s ± 1.96 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1\n",
    "conf = (SparkConf().setAppName(\"implicit_benchmark\").setMaster('local[2]'))\n",
    "sc = SparkContext.getOrCreate(conf=conf)\n",
    "spark = SQLContext(sc)\n",
    "\n",
    "datosGlobales=read_file(\"segmented_TopFixed.gpkg\")\n",
    "datosEntrenamiento=read_file(\"ForClassifySegments.gpkg\")\n",
    "\n",
    "dfGlobal=spark.createDataFrame(datosGlobales)\n",
    "dfEntrenamiento=spark.createDataFrame(datosEntrenamiento)\n",
    "dfE=dfEntrenamiento.select(\"cat\",\"tipo\").join(dfGlobal,\"cat\",\"inner\")\n",
    "\n",
    "columnas=['area', 'perimeter',  'fd', 'perimeter', 'compact_circle', 'fd', 'B1_sum', 'B1_mean', 'B1_median', 'B1_stdev', 'B1_min', 'B1_max', 'B1_variance', 'B2_sum', 'B2_mean', 'B2_median', 'B2_stdev', 'B2_min', 'B2_max', 'B2_variance', 'B3_sum', 'B3_mean', 'B3_median', 'B3_stdev', 'B3_min', 'B3_max', 'B3_variance']\n",
    "constructor=VectorAssembler(inputCols=columnas,outputCol=\"features\")\n",
    "\n",
    "dfEF=constructor.transform(dfE).select(\"cat\",\"features\",\"tipo\")\n",
    "\n",
    "entrena,evalua=dfEF.randomSplit([0.8,0.2])\n",
    "\n",
    "rf=RandomForestClassifier(labelCol=\"tipo\")\n",
    "\n",
    "modelo=rf.fit(entrena)\n",
    "\n",
    "pred=modelo.transform(evalua)\n",
    "\n",
    "evaluador=MulticlassClassificationEvaluator(labelCol=\"tipo\",metricName=\"accuracy\")\n",
    "\n",
    "metrica=evaluador.evaluate(pred)\n",
    "\n",
    "if metrica>=0.75:\n",
    "    modeloOk=rf.fit(dfEF)\n",
    "    print(\"Se guarda el modelo a disco (métrica: \",metrica,\")\")\n",
    "    modeloOk.write().overwrite().save(\"modelorf\") #eliminar overwrite() si no se quiere sobreescribir el modelo\n",
    "else:\n",
    "    print(\"El modelo no es lo bastante bueno, métrica: \",metrica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo no es lo bastante bueno, métrica:  0.65\n",
      "Se guarda el modelo a disco (métrica:  0.8095238095238095 )\n",
      "Se guarda el modelo a disco (métrica:  0.8260869565217391 )\n",
      "Se guarda el modelo a disco (métrica:  0.76 )\n",
      "Se guarda el modelo a disco (métrica:  0.8695652173913043 )\n",
      "Se guarda el modelo a disco (métrica:  0.8148148148148148 )\n",
      "Se guarda el modelo a disco (métrica:  0.8823529411764706 )\n",
      "14.3 s ± 1.85 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1\n",
    "conf = (SparkConf().setAppName(\"implicit_benchmark\").setMaster('local[4]'))\n",
    "sc = SparkContext.getOrCreate(conf=conf)\n",
    "spark = SQLContext(sc)\n",
    "\n",
    "datosGlobales=read_file(\"segmented_TopFixed.gpkg\")\n",
    "datosEntrenamiento=read_file(\"ForClassifySegments.gpkg\")\n",
    "\n",
    "dfGlobal=spark.createDataFrame(datosGlobales)\n",
    "dfEntrenamiento=spark.createDataFrame(datosEntrenamiento)\n",
    "dfE=dfEntrenamiento.select(\"cat\",\"tipo\").join(dfGlobal,\"cat\",\"inner\")\n",
    "\n",
    "columnas=['area', 'perimeter',  'fd', 'perimeter', 'compact_circle', 'fd', 'B1_sum', 'B1_mean', 'B1_median', 'B1_stdev', 'B1_min', 'B1_max', 'B1_variance', 'B2_sum', 'B2_mean', 'B2_median', 'B2_stdev', 'B2_min', 'B2_max', 'B2_variance', 'B3_sum', 'B3_mean', 'B3_median', 'B3_stdev', 'B3_min', 'B3_max', 'B3_variance']\n",
    "constructor=VectorAssembler(inputCols=columnas,outputCol=\"features\")\n",
    "\n",
    "dfEF=constructor.transform(dfE).select(\"cat\",\"features\",\"tipo\")\n",
    "\n",
    "entrena,evalua=dfEF.randomSplit([0.8,0.2])\n",
    "\n",
    "rf=RandomForestClassifier(labelCol=\"tipo\")\n",
    "\n",
    "modelo=rf.fit(entrena)\n",
    "\n",
    "pred=modelo.transform(evalua)\n",
    "\n",
    "evaluador=MulticlassClassificationEvaluator(labelCol=\"tipo\",metricName=\"accuracy\")\n",
    "\n",
    "metrica=evaluador.evaluate(pred)\n",
    "\n",
    "if metrica>=0.75:\n",
    "    modeloOk=rf.fit(dfEF)\n",
    "    print(\"Se guarda el modelo a disco (métrica: \",metrica,\")\")\n",
    "    modeloOk.write().overwrite().save(\"modelorf\") #eliminar overwrite() si no se quiere sobreescribir el modelo\n",
    "else:\n",
    "    print(\"El modelo no es lo bastante bueno, métrica: \",metrica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo no es lo bastante bueno, métrica:  0.7368421052631579\n",
      "Se guarda el modelo a disco (métrica:  0.8 )\n",
      "Se guarda el modelo a disco (métrica:  0.8888888888888888 )\n",
      "Se guarda el modelo a disco (métrica:  0.8260869565217391 )\n",
      "Se guarda el modelo a disco (métrica:  0.8148148148148148 )\n",
      "Se guarda el modelo a disco (métrica:  0.8571428571428571 )\n",
      "El modelo no es lo bastante bueno, métrica:  0.6956521739130435\n",
      "13.3 s ± 1.79 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1\n",
    "conf = (SparkConf().setAppName(\"implicit_benchmark\").setMaster('local[6]'))\n",
    "sc = SparkContext.getOrCreate(conf=conf)\n",
    "spark = SQLContext(sc)\n",
    "\n",
    "datosGlobales=read_file(\"segmented_TopFixed.gpkg\")\n",
    "datosEntrenamiento=read_file(\"ForClassifySegments.gpkg\")\n",
    "\n",
    "dfGlobal=spark.createDataFrame(datosGlobales)\n",
    "dfEntrenamiento=spark.createDataFrame(datosEntrenamiento)\n",
    "dfE=dfEntrenamiento.select(\"cat\",\"tipo\").join(dfGlobal,\"cat\",\"inner\")\n",
    "\n",
    "columnas=['area', 'perimeter',  'fd', 'perimeter', 'compact_circle', 'fd', 'B1_sum', 'B1_mean', 'B1_median', 'B1_stdev', 'B1_min', 'B1_max', 'B1_variance', 'B2_sum', 'B2_mean', 'B2_median', 'B2_stdev', 'B2_min', 'B2_max', 'B2_variance', 'B3_sum', 'B3_mean', 'B3_median', 'B3_stdev', 'B3_min', 'B3_max', 'B3_variance']\n",
    "constructor=VectorAssembler(inputCols=columnas,outputCol=\"features\")\n",
    "\n",
    "dfEF=constructor.transform(dfE).select(\"cat\",\"features\",\"tipo\")\n",
    "\n",
    "entrena,evalua=dfEF.randomSplit([0.8,0.2])\n",
    "\n",
    "rf=RandomForestClassifier(labelCol=\"tipo\")\n",
    "\n",
    "modelo=rf.fit(entrena)\n",
    "\n",
    "pred=modelo.transform(evalua)\n",
    "\n",
    "evaluador=MulticlassClassificationEvaluator(labelCol=\"tipo\",metricName=\"accuracy\")\n",
    "\n",
    "metrica=evaluador.evaluate(pred)\n",
    "\n",
    "if metrica>=0.75:\n",
    "    modeloOk=rf.fit(dfEF)\n",
    "    print(\"Se guarda el modelo a disco (métrica: \",metrica,\")\")\n",
    "    modeloOk.write().overwrite().save(\"modelorf\") #eliminar overwrite() si no se quiere sobreescribir el modelo\n",
    "else:\n",
    "    print(\"El modelo no es lo bastante bueno, métrica: \",metrica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[cat: bigint, features: vector, tipo: bigint]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = (SparkConf().setAppName(\"implicit_benchmark\").setMaster('local[6]'))\n",
    "sc = SparkContext.getOrCreate(conf=conf)\n",
    "spark = SQLContext(sc)\n",
    "\n",
    "datosGlobales=read_file(\"segmented_TopFixed.gpkg\")\n",
    "datosEntrenamiento=read_file(\"ForClassifySegments.gpkg\")\n",
    "\n",
    "dfGlobal=spark.createDataFrame(datosGlobales)\n",
    "dfEntrenamiento=spark.createDataFrame(datosEntrenamiento)\n",
    "dfE=dfEntrenamiento.select(\"cat\",\"tipo\").join(dfGlobal,\"cat\",\"inner\")\n",
    "\n",
    "columnas=['area', 'perimeter',  'fd', 'perimeter', 'compact_circle', 'fd', 'B1_sum', 'B1_mean', 'B1_median', 'B1_stdev', 'B1_min', 'B1_max', 'B1_variance', 'B2_sum', 'B2_mean', 'B2_median', 'B2_stdev', 'B2_min', 'B2_max', 'B2_variance', 'B3_sum', 'B3_mean', 'B3_median', 'B3_stdev', 'B3_min', 'B3_max', 'B3_variance']\n",
    "constructor=VectorAssembler(inputCols=columnas,outputCol=\"features\")\n",
    "\n",
    "dfEF=constructor.transform(dfE).select(\"cat\",\"features\",\"tipo\")\n",
    "\n",
    "entrena,evalua=dfEF.randomSplit([0.8,0.2])\n",
    "\n",
    "rf=RandomForestClassifier(labelCol=\"tipo\")\n",
    "\n",
    "entrena.cache()\n",
    "evalua.cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.03 s ± 352 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1\n",
    "modelo=rf.fit(entrena)\n",
    "pred=modelo.transform(evalua)\n",
    "metrica=evaluador.evaluate(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"mailto:alberto@torredebabel.com\" style=\"text-decoration:none;\" title=\"Alberto Álvarez Vales\">\n",
    "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAYAAABXAvmHAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAALOSURBVGhD7ZhbbxJRFIX7Q/Tdn6hWjdEaE6PG2tqIokVa0lAQS4tRAVt6QbBylQoIJP4CjZfn5njWsAfodG9uaWEezkpWSmb22vsrnTmnOTNGRkZGRkZGblOl2bxYrDfDhXrrb7HeUtM0GAq1ZiRX/3GJ8PoL8IV68yfXbJrWTL/KjcYFwpSVKR9tcg3c4HSpGiVMWXOewPHr5D7bYJoG09yz1WPClHX5kVfBS8FNdVips80maTCAxeYiTFkb22l1bXHZKr7tWVWJbJ5tPAknswWLASxgAhthykJwv1BR95bXreCV+Rcq8Paj0ivBqQHnZczCTMwGA1jAhHuEKctuktdNfNF4p8mDVyH9En07Meg8jBkP/eHOlwcGsNj3CVNWbzP4/cEXdXPJbzW88cSnYrvZE/fP0rG9rDUDszATs501hCnLGYCzX2tqPvDGagx7I+9Uvto4VTeu0Qs97f6YhZlcLWHK4kKw3hFV8ENKzT5+aQ25611TqVyZrR3F6IFe6InemIFZXC1MmLK4UK93DkvqzvP2wKt6YCi+y9YNY2RnF9pfCHqiN1fXa8KUxYWczlW/K084Zg2GF9Y21OcR9gzULuqMnUcv9ORqnSZMWVxIcjSVUdfppbv1dEXFM4P3DNSgFhlk0YOrk0yYsrhQP6dLR+q+XmIBhGXPv5Vg9wxcW9H37GUZGWSddYNMmLK40CADzr+V7ML5Quqg2IXDZ1zr/pLJsTdGwpTFhYa19Xh4eh6PnU+WO4+ZvjfMY9bPhCmLC41i5wtqG9dGedElE6YsLjSOw4k9a4mE8ZmrGceEKYsLjWtsUmex2fWaMGVxITeZMGVxITeZMGVxITeZMGVxITeZMGXp/wT/cUFXuNb6Q5iy9A4ZYcMucKHWChKmLJyA4RCJazBN47BtqIMtqH202ArhT+ZsNHHXmr/1z/Wh4Y2MjIyMjIwmppmZ/5kF65N8du5VAAAAAElFTkSuQmCC\" width=\"26px\" height=\"26px\"></a>\n",
    "<a href=\"https://www.linkedin.com/in/albertoav\" style=\"text-decoration:none;\" title=\"Alberto Álvarez Vales\">\n",
    "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABoAAAAaCAYAAACpSkzOAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAFjSURBVEhLYxgFVAPMHZdcGdsvrmTsuLCbPHxxBXP7JReocdgByBKm9gv/mDou/qcIA83AaxnIJ1g1koFBPoMaiwmY2i8ehink6L70P2PHk/8+q+9jGEIUBpoFNRYTIFuUufPJfxD4B8QK065hGkQIE2sRyCcgS15/+/1feMIVTIMIYWItAmGl6dfJswSEibUocuPD/3vufwZjvbk3/ysDLYXxU7Y9/u+y/O7/hZff/V9y5d3/bGAwg+KULIsqDzwHxxEI2C25818faBkMnH/57f9fULgiga13PlLfIhDYDfTZupsfUCw0X3ibuhaBgg+mrvYQQh0oSGHiVLGo9+QruIGOS+9ARf//bz32kroWdRxHGAiSgwFk8VGLwICmFjkuu/u/8/grMAaVEFKTr8L5nqvuwQ0EyWETx2sR3aoJUGVFvYrvghPUWOwAZBnINdiraSJw+8XlzJ3nHaHGjQJKAQMDADrrGXR0IRUYAAAAAElFTkSuQmCC\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
